{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d945db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Obtaining dependency information for accelerate from https://files.pythonhosted.org/packages/9f/d2/c581486aa6c4fbd7394c23c47b83fa1a919d34194e16944241daf9e762dd/accelerate-1.12.0-py3-none-any.whl.metadata\n",
      "  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dorian\\documents\\mujoco_sim\\venv\\lib\\site-packages (from accelerate) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dorian\\documents\\mujoco_sim\\venv\\lib\\site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\dorian\\documents\\mujoco_sim\\venv\\lib\\site-packages (from accelerate) (7.1.3)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\dorian\\documents\\mujoco_sim\\venv\\lib\\site-packages (from accelerate) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\dorian\\documents\\mujoco_sim\\venv\\lib\\site-packages (from accelerate) (2.9.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in c:\\users\\dorian\\documents\\mujoco_sim\\venv\\lib\\site-packages (from accelerate) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\dorian\\documents\\mujoco_sim\\venv\\lib\\site-packages (from accelerate) (0.7.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\dorian\\documents\\mujoco_sim\\venv\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dorian\\documents\\mujoco_sim\\venv\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\dorian\\documents\\mujoco_sim\\venv\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\dorian\\documents\\mujoco_sim\\venv\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dorian\\documents\\mujoco_sim\\venv\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\dorian\\documents\\mujoco_sim\\venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\dorian\\documents\\mujoco_sim\\venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dorian\\documents\\mujoco_sim\\venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dorian\\documents\\mujoco_sim\\venv\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dorian\\documents\\mujoco_sim\\venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dorian\\documents\\mujoco_sim\\venv\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dorian\\documents\\mujoco_sim\\venv\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dorian\\documents\\mujoco_sim\\venv\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dorian\\documents\\mujoco_sim\\venv\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dorian\\documents\\mujoco_sim\\venv\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.10.5)\n",
      "Downloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "   ---------------------------------------- 0.0/380.9 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/380.9 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 61.4/380.9 kB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 256.0/380.9 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 380.9/380.9 kB 3.4 MB/s eta 0:00:00\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969d37d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import AutoModelForVision2Seq, AutoProcessor\n",
    "import mujoco\n",
    "\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add franka_table parent directory to path\n",
    "sys.path.insert(0, str(Path().resolve().parent))\n",
    "\n",
    "from environments.franka_4robots_env import FrankaTable4RobotsEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06864f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m torch.cuda.empty_cache()  \u001b[38;5;66;03m# Clear any cached memory\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCUDA available: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch.cuda.is_available()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCurrent device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDevice count: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch.cuda.device_count()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dorian\\Documents\\mujoco_sim\\venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:1069\u001b[39m, in \u001b[36mcurrent_device\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1067\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcurrent_device\u001b[39m() -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m   1068\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Return the index of a currently selected device.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1069\u001b[39m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1070\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch._C._cuda_getDevice()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Dorian\\Documents\\mujoco_sim\\venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:403\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    399\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    400\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmultiprocessing, you must use the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mspawn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m start method\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    401\u001b[39m     )\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch._C, \u001b[33m\"\u001b[39m\u001b[33m_cuda_getDeviceCount\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTorch not compiled with CUDA enabled\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    404\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    406\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    407\u001b[39m     )\n",
      "\u001b[31mAssertionError\u001b[39m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()  # Clear any cached memory\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "print(f\"Device count: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa9064cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Franka Table 4-Robots Environment initialized:\n",
      "  - Number of robots: 4\n",
      "  - Number of actuators: 32 (8 per robot)\n",
      "  - Number of bodies: 47\n",
      "  - Number of joints (nq): 43\n",
      "  - Number of velocities (nv): 42\n",
      "  - Observation dimension: 80\n",
      "  - Action dimension: 32\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 1. Setup Environment\n",
    "# ============================================================================\n",
    "# Using a robot manipulation environment (e.g., Franka Panda)\n",
    "# Replace with your specific environment\n",
    "# env = gym.make(\n",
    "#     \"scenes/scene_4robots.xml\",  # custom MuJoCo env\n",
    "#     render_mode=\"rgb_array\"\n",
    "# )\n",
    "\n",
    "env_scene = \"../scenes/scene_4robots.xml\"\n",
    "render_mode = \"rgb_array\"\n",
    "env = FrankaTable4RobotsEnv(mjcf_path=env_scene, render_mode=render_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c292f1e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lerobot.common'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m sys.path.insert(\u001b[32m0\u001b[39m, \u001b[38;5;28mstr\u001b[39m(Path().resolve().parent.parent.parent))\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlerobot\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpolicies\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msmolvla\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodeling_smolvla\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SmolVLAPolicy\n\u001b[32m      4\u001b[39m policy = SmolVLAPolicy.from_pretrained(\u001b[33m\"\u001b[39m\u001b[33mlerobot/smolvla_base\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'lerobot.common'"
     ]
    }
   ],
   "source": [
    "sys.path.insert(0, str(Path().resolve().parent.parent.parent))\n",
    "\n",
    "from lerobot.src.common.policies.smolvla.modeling_smolvla import SmolVLAPolicy\n",
    "policy = SmolVLAPolicy.from_pretrained(\"lerobot/smolvla_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1417ae9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading OpenVLA model with GPU optimizations...\n",
      "Using device: CUDA device not found. A GPU is required to run this model.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 2. Load OpenVLA Model (GPU Optimized)\n",
    "# ============================================================================\n",
    "print(\"Loading OpenVLA model with GPU optimizations...\")\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else ValueError(\"CUDA device not found. A GPU is required to run this model.\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"HuggingFaceTB/SmolVLM-Instruct\", trust_remote_code=True)\n",
    "\n",
    "vla = AutoModelForVision2Seq.from_pretrained(\n",
    "    \"HuggingFaceTB/SmolVLM-Instruct\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    trust_remote_code=True,\n",
    "    attn_implementation=\"flash_attention_2\",  # Flash Attention 2 for speed (requires flash-attn package)\n",
    ")\n",
    "\n",
    "print(f\"Model loaded successfully on {device}!\")\n",
    "print(f\"Model device: {vla.device}\")\n",
    "print(f\"Model dtype: {vla.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfd861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 3. Helper Functions\n",
    "# ============================================================================\n",
    "\n",
    "def get_robot_state_7d(env, robot_idx=0):\n",
    "    \"\"\"\n",
    "    Extract 7D state (position + quaternion) for a specific robot's end-effector.\n",
    "    \n",
    "    Args:\n",
    "        env: FrankaTable4RobotsEnv instance\n",
    "        robot_idx: Which robot (0-3)\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: [x, y, z, qw, qx, qy, qz]\n",
    "    \"\"\"\n",
    "    prefix = env.robot_prefixes[robot_idx]\n",
    "    gripper_site_name = f\"{prefix}gripper_site\"\n",
    "    \n",
    "    # Get site ID\n",
    "    import mujoco\n",
    "    gripper_site_id = mujoco.mj_name2id(\n",
    "        env.model, \n",
    "        mujoco.mjtObj.mjOBJ_SITE, \n",
    "        gripper_site_name\n",
    "    )\n",
    "    \n",
    "    if gripper_site_id >= 0:\n",
    "        # Get position\n",
    "        position = env.data.site_xpos[gripper_site_id].copy()  # [x, y, z]\n",
    "        \n",
    "        # Get orientation (quaternion in MuJoCo format: [w, x, y, z])\n",
    "        quaternion = env.data.site_xquat[gripper_site_id].copy()  # [w, x, y, z]\n",
    "        \n",
    "        # Combine into 7D state\n",
    "        state_7d = np.concatenate([position, quaternion])\n",
    "        return state_7d\n",
    "    else:\n",
    "        # Fallback if site not found\n",
    "        return np.zeros(7)\n",
    "\n",
    "def get_observation(env, robot_idx=0, camera_name=None):\n",
    "    \"\"\"\n",
    "    Get RGB image and robot state from environment.\n",
    "    \n",
    "    Args:\n",
    "        env: FrankaTable4RobotsEnv instance\n",
    "        robot_idx: Which robot to get state for (0-3)\n",
    "        camera_name: Optional camera name for specific view\n",
    "    \n",
    "    Returns:\n",
    "        image: PIL Image\n",
    "        state_7d: np.ndarray of shape (7,) - [x, y, z, qw, qx, qy, qz]\n",
    "    \"\"\"\n",
    "    # Get RGB image\n",
    "    if camera_name:\n",
    "        rgb_array = env.render_camera(camera_name, width=640, height=480)\n",
    "    else:\n",
    "        rgb_array = env.render()\n",
    "    \n",
    "    image = Image.fromarray(rgb_array)\n",
    "    \n",
    "    # Get 7D state for the specified robot\n",
    "    state_7d = get_robot_state_7d(env, robot_idx)\n",
    "    \n",
    "    return image, state_7d\n",
    "\n",
    "def format_prompt(task_description):\n",
    "    \"\"\"Format the prompt for OpenVLA\"\"\"\n",
    "    return f\"In: What action should the robot take to {task_description}?\\nOut:\"\n",
    "\n",
    "def vla_action_to_env_action(vla_action, robot_idx, env):\n",
    "    \"\"\"\n",
    "    Convert VLA 7-DoF action to environment's 32-actuator action.\n",
    "    \n",
    "    VLA action: [dx, dy, dz, droll, dpitch, dyaw, gripper]\n",
    "    Env action: 32 values (8 per robot × 4 robots)\n",
    "    \n",
    "    This is a simplified mapping - you may need more sophisticated IK.\n",
    "    \n",
    "    Args:\n",
    "        vla_action: np.ndarray of shape (7,) from VLA\n",
    "        robot_idx: Which robot this action is for (0-3)\n",
    "        env: FrankaTable4RobotsEnv instance\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray of shape (32,) for environment\n",
    "    \"\"\"\n",
    "    # Start with current control values (hold other robots steady)\n",
    "    full_action = env.data.ctrl.copy()\n",
    "    \n",
    "    # Extract components from VLA action\n",
    "    delta_pos = vla_action[:3]  # [dx, dy, dz]\n",
    "    delta_rot = vla_action[3:6]  # [droll, dpitch, dyaw]\n",
    "    gripper = vla_action[6]  # gripper command\n",
    "    \n",
    "    # Get current robot joint positions\n",
    "    qpos_start = 7 + robot_idx * 9\n",
    "    current_joints = env.data.qpos[qpos_start:qpos_start+7].copy()\n",
    "    \n",
    "    # Simple approach: small joint space movements\n",
    "    # For a real implementation, you'd use inverse kinematics here\n",
    "    # This just applies small deltas to current joint positions\n",
    "    joint_deltas = np.zeros(7)\n",
    "    joint_deltas[0] = delta_pos[0] * 0.1  # Scale down for stability\n",
    "    joint_deltas[1] = delta_pos[1] * 0.1\n",
    "    joint_deltas[2] = delta_pos[2] * 0.1\n",
    "    joint_deltas[3] = delta_rot[0] * 0.1\n",
    "    joint_deltas[4] = delta_rot[1] * 0.1\n",
    "    joint_deltas[5] = delta_rot[2] * 0.1\n",
    "    \n",
    "    # Apply to the specific robot's actuators\n",
    "    ctrl_start = robot_idx * 8\n",
    "    full_action[ctrl_start:ctrl_start+7] = current_joints + joint_deltas\n",
    "    \n",
    "    # Set gripper (maps -1 to 1 → 0 to 255)\n",
    "    gripper_value = (gripper + 1) * 127.5  # Map [-1, 1] to [0, 255]\n",
    "    full_action[ctrl_start+7] = np.clip(gripper_value, 0, 255)\n",
    "    \n",
    "    return full_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfe45fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 4. Main Control Loop\n",
    "# ============================================================================\n",
    "def run_episode(task_description=\"pick up the object\", max_steps=100):\n",
    "    \"\"\"Run one episode with VLA control\"\"\"\n",
    "    \n",
    "    obs, info = env.reset()\n",
    "    prompt = format_prompt(task_description)\n",
    "    \n",
    "    print(f\"\\nTask: {task_description}\")\n",
    "    print(f\"Running for {max_steps} steps...\\n\")\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        # Get current observation\n",
    "        image, state_7d = get_observation(env)\n",
    "        \n",
    "        # Prepare inputs for VLA\n",
    "        inputs = processor(prompt, image).to(\"cuda:0\", dtype=torch.bfloat16)\n",
    "        \n",
    "        # Predict action (7-DoF: delta_pos[3] + delta_rot[3] + gripper[1])\n",
    "        with torch.no_grad():\n",
    "            action = vla.predict_action(\n",
    "                **inputs,\n",
    "                unnorm_key=\"bridge_orig\",\n",
    "                do_sample=False\n",
    "            )\n",
    "        \n",
    "        # Convert to numpy and ensure correct shape\n",
    "        action = action.cpu().numpy()\n",
    "        if action.ndim > 1:\n",
    "            action = action[0]\n",
    "        \n",
    "        # Step environment\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        \n",
    "        # Print progress\n",
    "        if step % 10 == 0:\n",
    "            print(f\"Step {step}: action = {action}, reward = {reward:.3f}\")\n",
    "        \n",
    "        # Check if episode is done\n",
    "        if terminated or truncated:\n",
    "            print(f\"\\nEpisode finished at step {step}\")\n",
    "            break\n",
    "    \n",
    "    return step"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
